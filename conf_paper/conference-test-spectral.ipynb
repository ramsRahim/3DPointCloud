{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../Project_Clustering')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "import myClusterPackage as myPack\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from mySpectralClustering import spectralFeatures\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting point cloud features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face_db = []\n",
    "#face_list = []\n",
    "#labels = []\n",
    "\n",
    "\n",
    "#data_folder = os.listdir(\"../3DFACEPAPER/Data/\") # list of all subfolder within Data folder\n",
    "#data_folder.remove('.DS_Store') \n",
    "\n",
    "\n",
    "#for k, expressions in enumerate (data_folder): # will loop within the main folder\n",
    "   \n",
    "    # Accessing each subfolder (expression) within the data folder  \n",
    "#    path =  \"../3DFACEPAPER/Data/\" + expressions +\"/\"\n",
    "#    face_names = os.listdir(path)    # list of all file names within subfolder\n",
    "    \n",
    "   \n",
    "#    for face in face_names: # will loop within the subfolder\n",
    "        \n",
    "#        if not face.startswith('.'):\n",
    "       # import the face and face labels\n",
    "#            file_name = path + face\n",
    "        \n",
    "#            df_face = pd.read_csv(file_name)\n",
    "#            face_list.append (df_face.values)\n",
    "#            labels.append (expressions)\n",
    "            \n",
    "\n",
    "#pickle.dump(face_list, open('face_data_full','wb'))\n",
    "#pickle.dump (labels, open('face_labels_full', 'wb'))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_list = pickle.load(open('face_data_full', 'rb'))\n",
    "face_labels = pickle.load(open('face_labels_full', 'rb'))\n",
    "\n",
    "all_patch_data = []\n",
    "n_face = len(face_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib tk\n",
    "\n",
    "\n",
    "#fig02 = plt.figure(figsize=(15,8))\n",
    "#ax = Axes3D(fig02)   \n",
    "#print (face_list[40])\n",
    "#for k in range (1):\n",
    "#    mvpk = np.where(face_list[k][:,2]==max(face_list[k][:,2]))\n",
    "    #mvpk = \n",
    "#    ax.scatter(face_list[k][:,0]-face_list[k][mvpk,0], \n",
    "#               face_list[k][:,1]-face_list[k][mvpk,1],\n",
    "#              face_list[k][:,2]- face_list[k][mvpk,2])\n",
    "\n",
    "#km01 = KMeans(\n",
    "#        n_clusters=8, init='k-means++',\n",
    "#        n_init=10, max_iter=300, \n",
    " #       tol=1e-04, random_state=10\n",
    " #   )\n",
    "\n",
    "#mvpk = np.where(face_list[0][:,2]== max(face_list[0][:,2]))\n",
    "#faceo = face_list[0] - face_list[0][mvpk]\n",
    "\n",
    "#transFeature = spectralFeatures (face_list,n_dim = 3, n_neighbor = 10)\n",
    "#df_3Col = transFeature.values    \n",
    "    \n",
    "#km01 = km01.fit(df_3Col)\n",
    "#init_centroids = km01.cluster_centers_\n",
    "#ax.scatter(init_centroids[:,0], init_centroids[:,1], init_centroids[:,2],'r', s=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pool = Pool()\n",
    "\n",
    "#pool.imap(Fun, product(xrange(N), xrange(N))), chunksize\n",
    "km = KMeans(\n",
    "        n_clusters=8, init='k-means++',\n",
    "        n_init=1, max_iter=300, \n",
    "        tol=1e-04, random_state=10\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "  #  mvpk = np.where(face[:,2]== max(face[:,2]))\n",
    "    \n",
    " #   face = face - face[mvpk[0][0]]\n",
    "#def specFeature (face, km):\n",
    "for i,face in enumerate(face_list):\n",
    "    \n",
    "\n",
    "\n",
    "    mvpk = np.where(face[:,2]== max(face[:,2]))\n",
    "    \n",
    "    face = face - face[mvpk[0][0]]\n",
    "\n",
    "    total_features = []\n",
    "    \n",
    "    \n",
    "    transFeature = spectralFeatures (face, n_dim = 3, n_neighbor = 10)\n",
    "    df_3Col = transFeature.values\n",
    "    \n",
    "    segments = km.fit_predict(df_3Col)\n",
    "    n_patch = len(np.unique(segments)) \n",
    "  #  centroids, _ = myPack.get_centroids(face, segments)\n",
    "    total_features = []\n",
    "   \n",
    "    for j in range (n_patch):\n",
    "        \n",
    "        patch_features = []\n",
    "        clusterLabels = []\n",
    "        featureLabels = []\n",
    "        \n",
    "        patch = face[segments == j]\n",
    "        \n",
    "        delta_patch = patch #- centroids [j] \n",
    "        \n",
    "  #      transFeature = spectralFeatures (delta_patch,n_dim = 2, n_neighbor = 10)\n",
    "   #     df_2Col = transFeature.values\n",
    "    \n",
    "        \n",
    "        ## Applying GMM on each patch\n",
    "        gmm = GaussianMixture(n_components = 3, covariance_type= 'diag',random_state=10)\n",
    "        patch_gmm = gmm.fit(delta_patch)\n",
    "        patch_w = patch_gmm.weights_\n",
    "        patch_mu = patch_gmm.means_\n",
    "        patch_sigma = patch_gmm.covariances_\n",
    "        \n",
    "        ## creating data frame for testing\n",
    "   #     n_features = len(patch_w) + len(patch_mu)*len(patch_mu[1]) #+ len(patch_sigma)*len(patch_sigma[1])\n",
    "    \n",
    "        # Features extracted from a single patch\n",
    "        # 3 + 6 + 6 --> repeated across 8 patches\n",
    "        patch_features = list(patch_w) + list(patch_mu.ravel())+ list(patch_sigma.ravel())\n",
    "        \n",
    "        # concatenating from all patches\n",
    "        total_features = total_features + patch_features\n",
    "    # adding features from all patches to the face database \n",
    "\n",
    "    \n",
    "df_3D_face = pd.DataFrame({'Patch_Features':all_patch_data,'Classes':face_labels})                                      \n",
    "\n",
    "# Encoding class labels \n",
    "le = preprocessing.LabelEncoder() \n",
    "df_3D_face['Labels']= le.fit_transform(df_3D_face['Classes']) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(8)\n",
    "\n",
    "#pool.imap(Fun, product(xrange(N), xrange(N))), chunksize\n",
    "\n",
    "for i,face in enumerate(pool.starmap(face_list)):\n",
    "    \n",
    "    \n",
    "    km = KMeans(\n",
    "        n_clusters=8, init='k-means++',\n",
    "        n_init=1, max_iter=300, \n",
    "        tol=1e-04, random_state=10\n",
    "    )\n",
    "\n",
    "  #  mvpk = np.where(face[:,2]== max(face[:,2]))\n",
    "    \n",
    " #   face = face - face[mvpk[0][0]]\n",
    "    \n",
    "    transFeature = spectralFeatures (face, n_dim = 3, n_neighbor = 10)\n",
    "    df_3Col = transFeature.values\n",
    "    \n",
    "    segments = km.fit_predict(df_3Col)\n",
    "    n_patch = len(np.unique(segments)) \n",
    "    centroids, _ = myPack.get_centroids(face, segments)\n",
    "    total_features = []\n",
    "   \n",
    "    for j in range (n_patch):\n",
    "        \n",
    "        patch_features = []\n",
    "        clusterLabels = []\n",
    "        featureLabels = []\n",
    "        \n",
    "        patch = face[segments == j]\n",
    "        \n",
    "        delta_patch = patch - centroids [j] \n",
    "        \n",
    "  #      transFeature = spectralFeatures (delta_patch,n_dim = 2, n_neighbor = 10)\n",
    "   #     df_2Col = transFeature.values\n",
    "    \n",
    "        \n",
    "        ## Applying GMM on each patch\n",
    "        gmm = GaussianMixture(n_components = 3, covariance_type= 'diag',random_state=10)\n",
    "        patch_gmm = gmm.fit(delta_patch)\n",
    "        patch_w = patch_gmm.weights_\n",
    "        patch_mu = patch_gmm.means_\n",
    "        patch_sigma = patch_gmm.covariances_\n",
    "        \n",
    "        ## creating data frame for testing\n",
    "   #     n_features = len(patch_w) + len(patch_mu)*len(patch_mu[1]) #+ len(patch_sigma)*len(patch_sigma[1])\n",
    "    \n",
    "        # Features extracted from a single patch\n",
    "        # 3 + 6 + 6 --> repeated across 8 patches\n",
    "        patch_features = list(patch_w) + list(patch_mu.ravel())+ list(patch_sigma.ravel())\n",
    "        \n",
    "        # concatenating from all patches\n",
    "        total_features = total_features + patch_features\n",
    "    # adding features from all patches to the face database \n",
    "    all_patch_data.append (total_features)\n",
    "\n",
    "df_3D_face = pd.DataFrame({'Patch_Features':all_patch_data,'Classes':face_labels})                                      \n",
    "\n",
    "# Encoding class labels \n",
    "le = preprocessing.LabelEncoder() \n",
    "df_3D_face['Labels']= le.fit_transform(df_3D_face['Classes']) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3D_face.to_pickle(\"all_face_features_spec.pkl\")\n",
    "\n",
    "\n",
    "#df_3D_face ['Classes'].unique()\n",
    "df_3D_face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 22), (4, 33), (5, 44)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def billbo (x,y):\n",
    "    \n",
    "    z = x*y;\n",
    "    \n",
    "    return z \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    alldata = []\n",
    "    p= [3, 4, 5]\n",
    "    q = [22, 33, 44]\n",
    "\n",
    "    pool = Pool(8)\n",
    "\n",
    "    data = [(p[i], q[i]) for i in range(3)]\n",
    "     \n",
    "    xx =pool.starmap(billbo,data)\n",
    "    #feaVec = pool.map(square, range(0, 5))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cut off 0.001\n",
    "#fea_indx = np.array([ 0, 1, 2, 3, 5, 7, 15, 16, 17, 18, 20, 21, 22, 30, 31, \n",
    "#       32, 36, 45, 46, 47, 49, 51, 60, 61, 62, 63, 64, 65, 66, 67, 75, 76, \n",
    "#       77, 78, 80, 82, 90, 91, 94, 105, 106, 107, 108, 110, 111, 112, 113])\n",
    "\n",
    "#Cut off 0.002\n",
    "#fea_indx = np.array([ 0, 1, 2, 15, 16, 17, 30, 31, 32, \n",
    "#       36, 45, 46, 47, 61, 75, 77, 90, 91, 105, 106, 107])\n",
    "\n",
    "#fea_indx =np.array([ 1, 2, 15, 30, 31 , 46, 77, 91, 105, 106])\n",
    "\n",
    "# Load pickle file\n",
    "df_3D_face = pd.read_pickle(\"all_face_features_lar.pkl\")\n",
    "\n",
    "xx = df_3D_face['Patch_Features'].to_list() \n",
    "\n",
    "data_mat = np.array (xx)\n",
    "\n",
    "face_labels = df_3D_face['Labels'].to_list() \n",
    "\n",
    "n_labels = len(np.unique(face_labels)) \n",
    "\n",
    "#dataMatrix = data_mat   # [:, fea_indx]\n",
    "\n",
    "data_matrix = data_mat# preprocessing.scale(data_mat)\n",
    "\n",
    "print (len(data_matrix[1]))\n",
    "\n",
    "df_3D_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df_3D_face.copy()\n",
    "\n",
    "# Performing PCA on raw data \n",
    "pca = PCA(n_components=5)\n",
    "pca_result = pca.fit_transform(data_matrix)\n",
    "df['pca-one'] = pca_result[:,0]\n",
    "df['pca-two'] = pca_result[:,1] \n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.scatterplot(\n",
    "    x=\"pca-one\", y=\"pca-two\",\n",
    "    hue=\"Classes\",\n",
    "    palette=sns.color_palette(\"hls\", n_labels),\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "    alpha=1.0\n",
    ")\n",
    "\n",
    "# Performing t-SNE on raw data\n",
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=10, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(data_matrix)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "df['tsne-2d-one'] = tsne_results[:,0]\n",
    "df['tsne-2d-two'] = tsne_results[:,1]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"Classes\",\n",
    "    palette=sns.color_palette(\"hls\", n_labels),\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "    alpha=1.0\n",
    ")\n",
    "\n",
    "# Performing t-SNE on PCA data \n",
    "tsne_results = tsne.fit_transform(pca_result[:,0:3])\n",
    "#print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "df['tsne-2d-one'] = tsne_results[:,0]\n",
    "df['tsne-2d-two'] = tsne_results[:,1]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"Classes\",\n",
    "    palette=sns.color_palette(\"hls\", n_labels),\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "    alpha=1.0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import ( pipeline, preprocessing, linear_model)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from matplotlib import pyplot as plt\n",
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "#70% taining, 20% validating 10% testing\n",
    "# 10x2 nested cross-validation \n",
    "# K-fold cross-validation - 1 fold -, 2-fold, average \n",
    "# 80% - 20%\n",
    "\n",
    "print ('Number of features', len(data_matrix[1]))\n",
    "\n",
    "# 10-fold cross-validation\n",
    "# Each fold test - 35, train - 315\n",
    "#Kaggle \n",
    "nfolds = 10\n",
    "clf = GradientBoostingClassifier(n_estimators= 5,\n",
    "                         #       class_weight = \"balanced\",\n",
    "                                random_state=42#,cache_size=20000\n",
    "                               # n_jobs=1\n",
    "                               )\n",
    "\n",
    "#pca = PCA ()   \n",
    "\n",
    "pipe = pipeline.Pipeline([  ('scl', preprocessing.StandardScaler()),\n",
    "                        #   ('pca', pca),\n",
    "                            ('clf', clf) \n",
    "                           \n",
    "                         \n",
    "                         ])\n",
    "    \n",
    "param_grid = { # \"pca__n_components\": [5, 10, 15, 30, 40],\n",
    "                      \"clf__n_estimators\":[10, 20, 30, 40, 50, 80,100],\n",
    "              \"clf__min_samples_split\": [2, 5, 10, 15],\n",
    "            \"clf__learning_rate\":[0.1, .02, 0.5],\n",
    "             \"clf__max_depth\": [2, 5, 10, 15],\n",
    "             }\n",
    "    \n",
    "    \n",
    "        \n",
    "kfold = StratifiedKFold(n_splits= nfolds, random_state= 42, shuffle=True)\n",
    "    \n",
    "\n",
    " \n",
    "\n",
    "fold_auc = []\n",
    "testPredict = []\n",
    "Stest = []\n",
    "\n",
    "for k, (train, test) in enumerate (kfold.split(data_matrix,face_labels)):\n",
    "         \n",
    "        # Accumulating training fold data and labels\n",
    "        trfold = [data_matrix [x] for x in train]\n",
    "        trSen  = [face_labels[x] for x in train]\n",
    "        \n",
    "   \n",
    "        # Accumulating test fold data and labels\n",
    "        tsfold = [data_matrix[x] for x in test]\n",
    "        tsSen = [face_labels[x] for x in test]\n",
    "        \n",
    "        \n",
    "        \n",
    "        gsModel = GridSearchCV(estimator=pipe, \n",
    "                                  param_grid = param_grid, n_jobs=1,\n",
    "                                  scoring = 'accuracy', cv = 2)\n",
    "         \n",
    "       \n",
    "        \n",
    "        # training the model \n",
    "        trModel = gsModel.fit(trfold,trSen)\n",
    "        \n",
    "        bestModel = trModel.best_estimator_\n",
    "        \n",
    "        print (bestModel)\n",
    "        \n",
    "        testPred =  bestModel.predict(tsfold)\n",
    "        \n",
    "        ##### Predict Probability ############\n",
    "        \n",
    "        probas =  bestModel.predict_proba(tsfold)\n",
    "        \n",
    "        \n",
    "        roc_auc =[]\n",
    "        for t in range (len(np.unique(face_labels))):\n",
    "            \n",
    "            fpr, tpr, _ = roc_curve(tsSen,probas[:,t], pos_label=t)        \n",
    "            roc_auc.append( auc(fpr,tpr))\n",
    "            \n",
    "        \n",
    "        \n",
    "        fold_auc.append (np.mean(roc_auc))\n",
    "        \n",
    "        \n",
    "        testPredict.extend (testPred)\n",
    "        Stest.extend (tsSen)\n",
    "        \n",
    "       # print ('Accuracy is:',accuracy_score( tsSen, testPred))\n",
    "    \n",
    "#    print(datetime.datetime.now().time())\n",
    "print ('Mean 10-fold AUC', np.mean(fold_auc))\n",
    "print ('Std 10-fold AUC', np.std(fold_auc))\n",
    "    \n",
    "#    return Stest, testPredict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAccuracy (fileName,Stest, testPredict):\n",
    "    \n",
    "    \n",
    "    #Stest = tsSen\n",
    "    cMatrix = confusion_matrix(Stest,testPredict)\n",
    "\n",
    "    # Converts each value in the matrix into a percentage/float-value\n",
    "    cMatrix = cMatrix.astype('float') / cMatrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Convert this list into a numpy array\n",
    "    Sent_test = np.asarray(Stest, dtype=np.int) \n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    # The tick labels for the box-plot\n",
    "    sent_label = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise'] \n",
    "    sent_label = np.asarray(sent_label, dtype=np.str)\n",
    "    sent_label = sent_label[unique_labels(Stest, testPredict)]\n",
    "    \n",
    "    print (sent_label)\n",
    "\n",
    "    # (cmap = plt.cm.Greens) represents the colors/shades used for the plot\n",
    "    im = ax.imshow(cMatrix, interpolation='nearest', cmap=plt.cm.Greys)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    \n",
    "    # Configures the labels and tick marks of the box-plot\n",
    "\n",
    "\n",
    "    ax.set(xticks=np.arange(cMatrix.shape[0] ),\n",
    "       yticks=np.arange(cMatrix.shape[0]),\n",
    "       \n",
    "       # Label the ticks with their respective sentiment\n",
    "       xticklabels=sent_label, yticklabels= sent_label,\n",
    "       \n",
    "       # Label the sides\n",
    "       title='Confusion Matrix',\n",
    "       ylabel='True Expression',\n",
    "       xlabel='Predicted Expression')\n",
    "   \n",
    "    ax.set_ylim(6.5,-0.5) \n",
    "    # Rotates and aligns the tick labels to be upright and centered\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f'\n",
    "    thresh = cMatrix.max() / 2.\n",
    "\n",
    "    for i in range(cMatrix.shape[0]):\n",
    "        for j in range(cMatrix.shape[0]):\n",
    "            ax.text(j, i, format(cMatrix[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cMatrix[i, j] > thresh else \"black\")\n",
    "\n",
    "    # A report of something, not sure though...\n",
    "  #  print(classification_report(Stest,testPredict))  \n",
    "\n",
    "    # The overall accuracy of our test\n",
    "    print('â€¢ Overall accuracy of the prediction/classifier model: ', accuracy_score(Sent_test, testPredict))\n",
    "\n",
    "    # Prints the fancy box-plot\n",
    "    #boxPlot.tight_layout()\n",
    "   # ax.axis('off')\n",
    "\n",
    "    fig.savefig(fileName, bbox_inches='tight', dpi=150)\n",
    "\n",
    "showAccuracy ('confusion_01.pdf',Stest, testPredict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
